{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Capstone Project: London Transport Policy Analysis**\n",
        "##**Exploratory Data Analysis**\n",
        "###Andrea Broaddus"
      ],
      "metadata": {
        "id": "zdRBONT1H93f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Data Cleaning**\n",
        "\n",
        "First we load the data and look at the feature types and sample data."
      ],
      "metadata": {
        "id": "OZIopI9FIWkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "3poPI7uQZFfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWM73-JEOnhG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/MLAI_Haas/data/London_CC_LSOA.csv')"
      ],
      "metadata": {
        "id": "FLyveo3NOvvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "hGMzKqzWPkLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "2AvMboPlXugc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1 Check for duplicates and outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "gzfoDMKAaQ-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for duplicates\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "HvaYq7CNbC-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "thQotCUCPshs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop non numeric features and features that will not be used as predictors\n",
        "X=data.drop(columns=['lsoa01', 'lsoa01_name', 'lsoa_area', 'car_time_2001'])\n",
        "X.shape"
      ],
      "metadata": {
        "id": "u0o-t_aAvo14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method of identifying outliers from https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset\n",
        "from collections import Counter\n",
        "\n",
        "def IQR_method (data,n,features):\n",
        "    \"\"\"\n",
        "    Takes a dataframe and returns an index list corresponding to the observations\n",
        "    containing more than n outliers according to the Tukey IQR method.\n",
        "    \"\"\"\n",
        "    outlier_list = []\n",
        "\n",
        "    for column in features:\n",
        "        # 1st quartile (25%)\n",
        "        Q1 = np.percentile(data[column], 25)\n",
        "        # 3rd quartile (75%)\n",
        "        Q3 = np.percentile(data[column],75)\n",
        "        # Interquartile range (IQR)\n",
        "        IQR = Q3 - Q1\n",
        "        # outlier step\n",
        "        outlier_step = 1.5 * IQR\n",
        "        # Determining a list of indices of outliers\n",
        "        outlier_list_column = data[(data[column] < Q1 - outlier_step) | (data[column] > Q3 + outlier_step )].index\n",
        "        # appending the list of outliers\n",
        "        outlier_list.extend(outlier_list_column)\n",
        "\n",
        "    # selecting observations containing more than x outliers\n",
        "    outlier_list = Counter(outlier_list)\n",
        "    multiple_outliers = list( k for k, v in outlier_list.items() if v > n )\n",
        "\n",
        "    # Calculate the number of records below and above lower and above bound value respectively\n",
        "    out1 = data[data[column] < Q1 - outlier_step]\n",
        "    out2 = data[data[column] > Q3 + outlier_step]\n",
        "\n",
        "    print('Total number of records below lower bound value: ', out1.shape[0])\n",
        "    print('Total number of records above upper bound value: ', out2.shape[0])\n",
        "\n",
        "    #Save the cleaned dataset\n",
        "    out1.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/outliers_below.csv', index=False)\n",
        "    out2.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/outliers_above.csv', index=False)\n",
        "\n",
        "    # Create a new column 'outlier' in data, initialized to 0\n",
        "    data['out_below'] = 0\n",
        "    data['out_above'] = 0\n",
        "    # Set 'outlier' to 1 for rows identified as outliers\n",
        "    data.loc[out1.index, 'out_below'] = 1\n",
        "    data.loc[out2.index, 'out_above'] = 1\n",
        "\n",
        "    print('Total number of detected outliers is:', out1.shape[0]+out2.shape[0])\n",
        "    print('Percentage of dataset that is outliers is:', (out1.shape[0]+out2.shape[0])/len(X))\n",
        "\n",
        "    return multiple_outliers"
      ],
      "metadata": {
        "id": "WLFNZX84TG_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detecting outliers\n",
        "numeric_columns=X.columns\n",
        "Outliers_IQR = IQR_method(data,1,numeric_columns)"
      ],
      "metadata": {
        "id": "geihTztjTNlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_tab = pd.crosstab(data['out_below'], data['cc'])\n",
        "print(cross_tab)"
      ],
      "metadata": {
        "id": "m8u5KtUu7pXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_tab = pd.crosstab(data['out_above'], data['cc'])\n",
        "print(cross_tab)"
      ],
      "metadata": {
        "id": "IScfIi977tZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 Summary of Data Cleaning\n",
        "\n",
        "*   All the features are numerical  \n",
        "*   No duplicates were found\n",
        "*   Many features have highly skewed distributions, therefore all data was normalized to be on the same scale\n",
        "*   328 cases (6.8%) were found to have outliers in multiple features, 44 of which were in the congestion charge zone, but since they were accurate data they were left in the dataset\n",
        "*   Many features have a significant percentage of null values, such as counts of large firms with over 500 employees which are only present in a few LSOAs. Since the null values represented counts of zero in other areas, nulls were replaced with zeroes in the dataset.\n"
      ],
      "metadata": {
        "id": "jFS744ewS92n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Data Exploration and Feature Engineering**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HUXk7kjSbeWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1 Feature Distributions\n",
        "\n",
        "Now we will use the cleaned and prepared dataset to look at the descriptive statistics, with visualizations, and make some observations.\n",
        "\n",
        "Comparison of feature changes inside and outside zone"
      ],
      "metadata": {
        "id": "QWTBl6OPOgte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the percentage of target features, it is highly imbalanced\n",
        "in_cc=data['cc']==1\n",
        "print(\"Number of LSOAs inside the Congestion Zone:\", in_cc.value_counts())\n",
        "print(\"Percentage of LSOAs inside the Congestion Zone:\", in_cc.value_counts(1),\"%)\")"
      ],
      "metadata": {
        "id": "1yMRFmwR1vOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace zeros with NaN for all columns except 'cc'\n",
        "for column in data.columns:\n",
        "    if column != 'cc':\n",
        "        data[column] = data[column].replace(0, np.nan)"
      ],
      "metadata": {
        "id": "xiKuCeahGYC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of population\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"pop_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Residents per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"pop_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "axs[1].legend(labels=['In CC zone', 'Not'])\n",
        "axs[1].set_title('Residents per LSOA 2011')\n",
        "axs[1].set_ylabel('Count of LSOAs')"
      ],
      "metadata": {
        "id": "Gjhnh1D-9Ur3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of employment\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"jobs_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Jobs per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"jobs_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "axs[1].legend(labels=['In CC zone', 'Not'])\n",
        "axs[1].set_title('Jobs per LSOA 2011')\n",
        "axs[1].set_ylabel('Count of LSOAs')"
      ],
      "metadata": {
        "id": "czT8hxYECY-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of car travel times\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"car_time_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Car travel time per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"car_time_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Car travel time per LSOA 2011')"
      ],
      "metadata": {
        "id": "z1WP8J5HCiDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of public transit travel times\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"pt_time_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Public transit travel time per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"pt_time_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Public transit travel time per LSOA 2011')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OPSZkD7uE1mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of office rent values\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"rent_off_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Average office rent per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"rent_off_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Average office rent LSOA 2011')\n"
      ],
      "metadata": {
        "id": "Ch6tLmZWFF41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of retail rent values\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"rent_ret_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Average retail rent per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"rent_ret_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Average retail rent LSOA 2011')"
      ],
      "metadata": {
        "id": "vAlaOgxtM7I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of office rent values\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"rent_whs_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Average warehouse rent per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"rent_whs_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Average warehouse rent LSOA 2011')"
      ],
      "metadata": {
        "id": "dxbEgM0eNCRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of large firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"large_firms_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Large firms per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"large_firms_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Large firms per LSOA 2011')"
      ],
      "metadata": {
        "id": "xV0oCQu1NUrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['lrg_firms_2001_log'] = np.log1p(data['large_firms_2001'])\n",
        "data['lrg_firms_2011_log'] = np.log1p(data['large_firms_2011'])"
      ],
      "metadata": {
        "id": "T9ht-t4WJSRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution log of large firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"lrg_firms_2001_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Large firms per LSOA 2001 Log')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"lrg_firms_2011_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Large firms per LSOA 2011 Log')"
      ],
      "metadata": {
        "id": "vO1BPQs-CHQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of medium firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"med_firms_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Medium firms per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"med_firms_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Medium firms per LSOA 2011')"
      ],
      "metadata": {
        "id": "1W_ePEiRA3eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['med_firms_2001_log'] = np.log1p(data['med_firms_2001'])\n",
        "data['med_firms_2011_log'] = np.log1p(data['med_firms_2011'])"
      ],
      "metadata": {
        "id": "R_tnhor_JYBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution log of medium firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"med_firms_2001_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Medium firms per LSOA 2001 Log')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"med_firms_2011_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Medium firms per LSOA 2011 Log')"
      ],
      "metadata": {
        "id": "s9Hyqlg0JgOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of small firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"small_firms_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Small firms per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"small_firms_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Small firms per LSOA 2011')"
      ],
      "metadata": {
        "id": "hN9DLucGA_13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['sm_firms_2001_log'] = np.log1p(data['small_firms_2001'])\n",
        "data['sm_firms_2011_log'] = np.log1p(data['small_firms_2011'])"
      ],
      "metadata": {
        "id": "s58HNmEvJ3Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution log of small firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"sm_firms_2001_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Small firms per LSOA 2001 Log')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"sm_firms_2011_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Small firms per LSOA 2011 Log')"
      ],
      "metadata": {
        "id": "64Mv5sAMJ3Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of micro firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"micro_firms_2001\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Micro firms per LSOA 2001')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"micro_firms_2011\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Micro firms per LSOA 2011')"
      ],
      "metadata": {
        "id": "qn_HUTFsPwt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['micro_firms_2001_log'] = np.log1p(data['micro_firms_2001'])\n",
        "data['micro_firms_2011_log'] = np.log1p(data['micro_firms_2011'])"
      ],
      "metadata": {
        "id": "kIFGsQwUJ5Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution log of micro firms\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.histplot(data=data, x=\"micro_firms_2001_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[0])\n",
        "axs[0].legend(labels=['In CC zone', 'Not'])\n",
        "axs[0].set_title('Micro firms per LSOA 2001 Log')\n",
        "axs[0].set_ylabel('Count of LSOAs')\n",
        "sns.histplot(data=data, x=\"micro_firms_2011_log\", hue='cc', multiple=\"dodge\", legend=False, ax=axs[1])\n",
        "plt.legend(labels=['In CC zone', 'Not'])\n",
        "plt.title('Micro firms per LSOA 2011 Log')"
      ],
      "metadata": {
        "id": "NLPr7poyJ5Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplots to check skewness, using code from https://www.kaggle.com/code/marcinrutecki/voting-classifier-for-better-results\n",
        "def boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n",
        "    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(25,25))\n",
        "    fig.suptitle(suptitle,y=1, size=25)\n",
        "    axs = axs.flatten()\n",
        "    for i, data in enumerate(columns_list):\n",
        "        sns.boxplot(data=dataset[data], orient='h', ax=axs[i])\n",
        "        axs[i].set_title(data + ', skewness is: '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n",
        "\n",
        "boxplots_custom(dataset=data, columns_list=X01, rows=9, cols=3, suptitle='Boxplots for each variable')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "-bMxp2f7PiXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37IA0S_YQ06E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the cleaned dataset\n",
        "data.to_csv('/content/drive/MyDrive/MLAI_Haas/data/London_CC_LSOA_cleaned.csv')"
      ],
      "metadata": {
        "id": "P4-EN3fsMGPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Observations\n",
        "\n",
        "\n",
        "*   Some features had highly skewed distributions, we we engineered new log features, for example firm population features\n",
        "*   The car_time feature for 2001 did not have a distribution at all; all values were 5 minutes access time. This means there was no differentiation between areas of London, in terms of car accessibility. This feature will be dropped, as it cannot provide any predictive power.\n",
        "*   This also means that the 2011 car_time feature is actually the difference from this uniform baseline in 2001, that is, it represents whether car access time increased or decreased over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "e2T9qk5uNhre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3 Correlations with congestion charge feature\n",
        "\n",
        "*   We expect to see the congestion charge zone indicator have a stronger correlation with features that are more prevalent inside the zone, for example, higher office rents, and weaker correlation with features that are less prevalent, like warehouse counts\n",
        "*   We also expect to see correlation between features that may overlap or be co-located in the same LSOAs, for example, higher office and retail rents, or higher counts of management consulting and business support firms\n",
        "*   We expect to see strong correlation between the same features in different years, for example, job counts for 2001 and 2011, versus percent change\n",
        "*   Some features are similar and have potential to be strongly correlated, so the aim is to select those with the most normal distribution and lowest amount of missing data. For example, the counts of firms by size (small, medium, large) versus aggregated together (nonmicro)"
      ],
      "metadata": {
        "id": "LsuEhXbwLi7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#New dataframes containing only LSOAs inside or outside the Congestion Charge zone\n",
        "data_cc = data[data[\"cc\"] == 1]\n",
        "data_notcc = data[data[\"cc\"] == 0]\n",
        "data_cc.shape"
      ],
      "metadata": {
        "id": "cVYSy4tFOvXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive statistics for LSOAs in the congestion zone\n",
        "data_cc[['pop_2001', 'jobs_2001', 'pt_time_2001', 'car_time_2001', 'large_firms_2001', 'micro_firms_2001' ]].describe()"
      ],
      "metadata": {
        "id": "xj4uQvqt7cOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive statistics for LSOAs not in the congestion zone\n",
        "data_notcc[['pop_2001', 'jobs_2001', 'pt_time_2001', 'car_time_2001', 'large_firms_2001', 'micro_firms_2001' ]].describe()"
      ],
      "metadata": {
        "id": "oZc2VrVl7ooG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2001 = data[['cc', 'afm_firms_2001', 'bizsup_firms_2001', 'comtelrd_firms_2001', 'creative_firms_2001', 'cult_firms_2001', 'devel_firms_2001', 'eduhsw_firms_2001', 'mgmt_firms_2001', 'pubutil_firms_2001', 'retail_firms_2001', 'tsp_firms_2001', 'ws_firms_2001']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2001, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population by Industry Category 2001\")"
      ],
      "metadata": {
        "id": "mKrS2D40RU7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2011 = data[['cc', 'afm_firms_2011', 'bizsup_firms_2011', 'comtelrd_firms_2011', 'creative_firms_2011', 'cult_firms_2011', 'devel_firms_2011', 'eduhsw_firms_2011', 'mgmt_firms_2011', 'pubutil_firms_2011', 'retail_firms_2011', 'tsp_firms_2011', 'ws_firms_2011']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2011, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population by Industry Category 2011\")"
      ],
      "metadata": {
        "id": "Q0z5CwiECISo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_pc = data[['cc', 'afm_pct_chg', 'bizsup_pct_chg', 'comtelrd_pct_chg', 'creative_pct_chg', 'cult_pct_chg', 'devel_pct_chg', 'eduhsw_pct_chg', 'mgmt_pct_chg', 'pubutil_pct_chg', 'retail_pct_chg', 'tsp_pct_chg', 'ws_pct_chg']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_pc, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population Change by Industry Category\")"
      ],
      "metadata": {
        "id": "03_HNCyVHwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2001 = data[['cc', 'jobs_2001', 'large_firms_2001', 'med_firms_2001', 'small_firms_2001', 'micro_firms_2001']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2001, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population 2001\")"
      ],
      "metadata": {
        "id": "-iUnDKqwCn4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2011 = data[['cc', 'jobs_2011', 'large_firms_2011', 'med_firms_2011', 'small_firms_2011', 'micro_firms_2011']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2011, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population 2011\")"
      ],
      "metadata": {
        "id": "_YrbpEBlFZrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data[['cc', 'jobs_pct_chg', 'large_pct_chg', 'med_pct_chg', 'small_pct_chg', 'micro_pct_chg']].corr(numeric_only = True)\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Firm Population Change\")"
      ],
      "metadata": {
        "id": "c6M0cwXmIGJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2001 = data[['cc', 'pop_2001', 'jobs_2001', 'pt_time_2001', 'rent_off_2001', 'rent_ret_2001', 'rent_whs_2001']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2001, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Jobs, Access and Rent Levels 2001\")"
      ],
      "metadata": {
        "id": "YQZb5770Fy3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_2011 = data[['cc', 'pop_2011', 'jobs_2011', 'car_time_2011', 'pt_time_2011', 'rent_off_2011', 'rent_ret_2011', 'rent_whs_2011']].corr(numeric_only = True)\n",
        "sns.heatmap(corr_2011, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Jobs, Access and Rent Levels 2011\")"
      ],
      "metadata": {
        "id": "-J3RJR11GYUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = data[['cc', 'pop_pct_chg', 'jobs_pct_chg', 'car_time_pct_chg', 'pt_time_pct_chg', 'rent_off_pct_chg', 'rent_ret_pct_chg', 'rent_whs_pct_chg']].corr(numeric_only = True)\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Jobs, Access and Rent Change\")"
      ],
      "metadata": {
        "id": "gUJI8OOmKTHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Feature Engineering**\n",
        "\n",
        "Now we split up the dataset into target and predictive features, and separated for analysis by year: 2001, 2011 and percent change. First we replace all null values with zeroes, to avoid issues with modeling.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G1wbPqQByeI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "jRvLZ2ftNPXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace all null values with zeroes\n",
        "data.replace(np.nan, 0, inplace=True)\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "Pq98kWriNQpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the target dataset\n",
        "#Save the y dataset\n",
        "y = data['cc']\n",
        "y.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/y.csv', index=False)\n",
        "y.info()"
      ],
      "metadata": {
        "id": "WE2vWAdv5aGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop non numeric features and features that will not be used as predictors\n",
        "X=data.drop(columns=['lsoa01', 'lsoa01_name', 'lsoa_area', 'car_time_2001'])\n",
        "X.shape"
      ],
      "metadata": {
        "id": "uv5aja9lyH8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Normalize all the features"
      ],
      "metadata": {
        "id": "7JwQre0T5sMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the predictors using StandardScalar\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# fit and transform the data\n",
        "scaled_data = StandardScaler().fit_transform(X)\n",
        "\n",
        "# create a new DataFrame with the scaled data\n",
        "X = pd.DataFrame(scaled_data, columns=X.columns)\n",
        "\n",
        "#Save scaled dataset\n",
        "X.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/X.csv')\n",
        "X.head()"
      ],
      "metadata": {
        "id": "oNlHrFT6XVkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Split into target and predictor datasets"
      ],
      "metadata": {
        "id": "4ahXYp_t55d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split scaled X features into sets representing 2001, 2011, and percent change predictors\n",
        "X01 = X.filter(regex='_2001')\n",
        "X11 = X.filter(regex='_2011')\n",
        "Xpc = X.filter(regex='_pct_chg')\n",
        "X01.info()\n",
        "#Save the 2001 Dataset\n",
        "X01.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/X01.csv', index=False)\n",
        "#Save the 2011 Dataset\n",
        "X11.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/X11.csv', index=False)\n",
        "#Save the Pct Chg Dataset\n",
        "Xpc.to_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/Xpc.csv', index=False)"
      ],
      "metadata": {
        "id": "PZx3-qSD5qZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LP2IPttfz2aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5. Summary of Observations**\n",
        "\n",
        "The final cleaned dataset has 149,861 vehicle listings. Now we will look at the descriptive statistics, with visualizations, and make some observations.\n",
        "\n",
        "##Summary of Observations\n",
        "All or nearly all listings included these attributes: Price, Year, Manufacturer, Model, Fuel, Odometer, Transmission.\n"
      ],
      "metadata": {
        "id": "8jZrO2ybz3DQ"
      }
    }
  ]
}