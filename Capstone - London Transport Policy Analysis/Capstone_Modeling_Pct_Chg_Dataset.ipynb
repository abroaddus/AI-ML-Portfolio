{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Capstone Project: London Transport Policy Analysis**\n",
        "## **Models for Percent Change Dataset**\n",
        "## Andrea Broaddus"
      ],
      "metadata": {
        "id": "ihfrzPUlKwfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **This notebook has three sections:**\n",
        "\n",
        "**1**.   Baseline Logistic Regression Model and Feature Selection\n",
        "\n",
        "**2**.   Comparison of Random Forest Classifiers Correcting for Imbalanced Dataset\n",
        "\n",
        "*     Model 1. Random Forest Baseline, no correction for imbalanced classes\n",
        "*   Model 2. Random Forest with Oversampling\n",
        "*   Model 3. Random Forest with Class Weights\n",
        "\n",
        "  \n",
        "**3**.   Neural Network Models\n",
        "\n",
        "*   Testing Optimization Algorithms\n",
        "*   Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "xzki69UrM3y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectPercentile, chi2, f_regression\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "3poPI7uQZFfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWM73-JEOnhG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the 2011 feature dataset\n",
        "Xpc = pd.read_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/Xpc.csv')\n",
        "Xpc.info()"
      ],
      "metadata": {
        "id": "HBT5ZDSMEfSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the target dataset\n",
        "y = pd.read_csv('/content/drive/MyDrive/MLAI_Haas/Capstone/y.csv')\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "_ndsefuEQy_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into train and test sets\n",
        "Xpc_train, Xpc_test, y_train, y_test = train_test_split(Xpc, y, test_size=0.3, random_state = 42)\n",
        "print(Xpc_train.shape)\n",
        "print(y_train.shape)\n",
        "print(Xpc_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "GbBwDl8ZlBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "DUd4jQ0j5mmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "id": "eKS5E5Cq6BM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Baseline Logistic Regression Model**"
      ],
      "metadata": {
        "id": "NiReYIkCRErS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimate a baseline Logistic Regression model\n",
        "random_seed = 42\n",
        "lr01=LogisticRegression(class_weight='balanced').fit(Xpc_train, y_train)\n",
        "lr01_train_preds = lr01.predict(Xpc_train)\n",
        "lr01_test_preds = lr01.predict(Xpc_test)\n",
        "lr01_report = classification_report(y_test, lr01_test_preds)\n",
        "print(lr01_report)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, lr01_test_preds)"
      ],
      "metadata": {
        "id": "x68Q99Twldri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the coefficients from the fitted estimator\n",
        "coefficients_01 = lr01.coef_[0]\n",
        "\n",
        "# Get the feature names\n",
        "feature_names_01 = Xpc_train.columns\n",
        "\n",
        "#Plot coefficients in order of importance\n",
        "feature_importance_01 = pd.DataFrame({'Feature': feature_names_01, 'Importance': np.float64(coefficients_01)})\n",
        "feature_importance_01 = feature_importance_01.sort_values('Importance', ascending=True)\n",
        "feature_importance_01.plot(x='Feature', y='Importance', kind='barh', figsize=(6,6))"
      ],
      "metadata": {
        "id": "vcxO4V-pmigh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Selection**\n"
      ],
      "metadata": {
        "id": "r1vK7sdd7c8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Select from Model tool with logistic regression to identify most valuable features\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "random_seed = 42\n",
        "lr01_select = SelectFromModel(LogisticRegression(C = .1, penalty = 'l1', solver = 'liblinear', class_weight='balanced', random_state = 42))\n",
        "lr01_select.fit_transform(Xpc_train, y_train)\n",
        "lr01_select_model = SelectFromModel(lr01_select, prefit=True)"
      ],
      "metadata": {
        "id": "1UFo09kb7hXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the coefficients from the fitted estimator\n",
        "coefficients = lr01_select.estimator_.coef_[0]\n",
        "\n",
        "# Assuming X_train is a pandas DataFrame with column names\n",
        "# Get the feature names from X_train.columns\n",
        "feature_names = Xpc_train.columns\n",
        "\n",
        "# Use get_support to get a boolean mask of the selected features\n",
        "support = lr01_select.get_support()\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_features = feature_names[support]\n",
        "\n",
        "# Get the coefficients corresponding to the selected features\n",
        "selected_coefficients = coefficients[support]\n",
        "\n",
        "#Plot coefficients in order of importance\n",
        "feature_importance = pd.DataFrame({'Feature': selected_features, 'Importance': np.float64(selected_coefficients)})\n",
        "feature_importance = feature_importance.sort_values('Importance', ascending=True)\n",
        "feature_importance.plot(x='Feature', y='Importance', kind='barh', figsize=(10, 6))"
      ],
      "metadata": {
        "id": "bSChd4RW8maw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Comparison of Classifiers Correcting for Imbalanced Dataset**\n",
        "\n",
        "This is a highly imbalanced dataset, with the target (positive) case only 2%. We will test three methods of correcting for imbalance and improving model preditive power.\n",
        "\n",
        "Two methods of correcting for an imbalanced target class were compared to a baseline Random Forest Classifier model using default settings. Each model was scored using stratified k-fold validation, and GridSearchCV was used for hyperparameter tuning.\n",
        "\n",
        "\n",
        "*   Model 1. Random Forest Baseline, no correction for imbalanced classes\n",
        "*   Model 2. Random Forest with Oversampling\n",
        "*   Model 3. Random Forest with Class Weights\n",
        "\n",
        "•\tBalancing class weights. The model parameter class_weight is set to “balanced,” meaning the classes will be weighted in the loss function inversely proportional to their frequency in the dataset. The estimator works to minimize the error on the more heavily weighted positive target class.\n",
        "\n",
        "•\tOversampling from the target class. The target feature is sampled to create a “balanced” dataset with 50% positive and negative cases, prior to running the estimator. In this method the negative cases are undersampled.\n"
      ],
      "metadata": {
        "id": "QZlOYu8BYoVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.metrics import roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay, DetCurveDisplay"
      ],
      "metadata": {
        "id": "kKRGAlx8hCD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall: The ability of a model to find all the relevant cases within a data set. The number of true positives divided by the number of true positives plus the number of false negatives.\n",
        "\n",
        "In most high-risk detection cases (like cancer), recall is a more important evaluation metric than precision.\n",
        "\n",
        "In the case of credit card fraud detection, we want to avoid false negatives as much as possible. Fraud transactions cost us a lot and thus we want to take appropriate measures to prevent them. A false negative case means that a fraud-positive transaction is assessed to genuine transaction, which is detrimental. In this use case, false positives (a genuine transaction as fraud-positive) are not as important as preventing a fraud.\n",
        "\n",
        "AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve.\n",
        "\n",
        "ROC is a probability curve and AUC represents the degree or measure of separability. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1."
      ],
      "metadata": {
        "id": "ZDhhuVKZV0yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 1. Random Forest Baseline, no correction for imbalanced classes**"
      ],
      "metadata": {
        "id": "YwjrSUZqXXO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline model with Random Forest classifier and no correction for class weights\n",
        "\n",
        "random_seed = 42\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=13)\n",
        "score = cross_val_score(rf, Xpc_train, np.ravel(y_train,order='C'), cv=kf, scoring='recall', verbose=0)\n",
        "\n",
        "print(\"Training Cross Validation Recall scores are: {}\".format(score))\n",
        "print(\"Training Average Cross Validation Recall score: {}\".format(score.mean()))"
      ],
      "metadata": {
        "id": "h397UX9DhP5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning Using GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [4, 6, 10, 12],\n",
        "    'random_state': [13]}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid=params, cv=kf,\n",
        "                          scoring='recall').fit(Xpc_train,np.ravel(y_train,order='C'))\n",
        "\n",
        "print('Best parameters:', grid_rf.best_params_)\n",
        "print('Best score:', grid_rf.best_score_)"
      ],
      "metadata": {
        "id": "6FXKZ3KuheaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation Metrics\n",
        "random_seed = 42\n",
        "y_pred = grid_rf.predict(Xpc_test)\n",
        "\n",
        "rf_Recall = recall_score(y_test, y_pred)\n",
        "rf_Precision = precision_score(y_test, y_pred)\n",
        "rf_f1 = f1_score(y_test, y_pred)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "ROCAUCscore = roc_auc_score(y_test, y_pred)\n",
        "print(f\"AUC-ROC Curve for Random Forest with No Under/Oversampling: {ROCAUCscore:.4f}\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ],
      "metadata": {
        "id": "sbA9jDB_ht0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "\n",
        "ndf = [(rf_Recall, rf_Precision, rf_f1, rf_accuracy)]\n",
        "\n",
        "rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
        "rf_score.insert(0, 'Random Forest with', 'No Under/Oversampling')\n",
        "rf_score"
      ],
      "metadata": {
        "id": "rt_7eWfghx1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 2. Random Forest with Oversampling**"
      ],
      "metadata": {
        "id": "7l_D9f7BYAOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Oversampling using imbalanced learning pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#Define oversampling strategy\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit and apply the transform\n",
        "X_over, y_over = ros.fit_resample(Xpc_train, y_train)\n",
        "\n",
        "# Convert y_over to a Pandas Series to use value_counts()\n",
        "#y_over_series = pd.Series(y_over)\n",
        "\n",
        "# Use y_over_series for value_counts()\n",
        "print('Genuine:', y_over.value_counts()[0], '/', round(y_over.value_counts()[0]/len(y_over) * 100,2), '% of the dataset')\n",
        "print('Frauds:', y_over.value_counts()[1], '/',round(y_over.value_counts()[1]/len(y_over) * 100,2), '% of the dataset')"
      ],
      "metadata": {
        "id": "Ernu9wx4h7ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imbalanced Learning Pipeline\n",
        "from imblearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "#Define and train the model\n",
        "random_seed = 42\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "random_overs_pipeline = make_pipeline(RandomOverSampler(random_state=42),\n",
        "                              RandomForestClassifier(n_estimators=100, random_state=13))\n",
        "\n",
        "#Score the model\n",
        "score2 = cross_val_score(random_overs_pipeline, Xpc_train, y_train, scoring='recall', cv=kf)\n",
        "\n",
        "print(\"Training Cross Validation Recall Scores are: {}\".format(score2))\n",
        "print(\"Training Average Cross Validation Recall score: {}\".format(score2.mean()))"
      ],
      "metadata": {
        "id": "_B_iTpGYiHq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use GridSearch to tune the hyperparameters\n",
        "random_seed = 42\n",
        "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
        "grid_over_rf = GridSearchCV(random_overs_pipeline, param_grid=new_params, cv=kf, scoring='recall',\n",
        "                        return_train_score=True)\n",
        "grid_over_rf.fit(Xpc_train, y_train)\n",
        "\n",
        "print('Best parameters:', grid_over_rf.best_params_)\n",
        "print('Best score:', grid_over_rf.best_score_)"
      ],
      "metadata": {
        "id": "mScpxCOHiSBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation Metrics\n",
        "random_seed = 42\n",
        "y_pred = grid_over_rf.best_estimator_.named_steps['randomforestclassifier'].predict(Xpc_test)\n",
        "\n",
        "over_rf_Recall = recall_score(y_test, y_pred)\n",
        "over_rf_Precision = precision_score(y_test, y_pred)\n",
        "over_rf_f1 = f1_score(y_test, y_pred)\n",
        "over_rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "ROCAUCscore = roc_auc_score(y_test, y_pred)\n",
        "print(f\"AUC-ROC Curve for Random Forest with Random Oversampling: {ROCAUCscore:.4f}\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ORdvmBH-iYha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "ndf = [(over_rf_Recall, over_rf_Precision, over_rf_f1, over_rf_accuracy)]\n",
        "\n",
        "over_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
        "over_rf_score.insert(0, 'Random Forest with', 'Random Oversampling')\n",
        "over_rf_score"
      ],
      "metadata": {
        "id": "Xmcslfu1iZGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 3. Random Forest with Class Weights**"
      ],
      "metadata": {
        "id": "WlynoNXyYI3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Random Forest classifier using class weight parameter\n",
        "random_seed = 42\n",
        "rfb = RandomForestClassifier(n_estimators=100, random_state=13, class_weight=\"balanced\")\n",
        "\n",
        "#Score the model\n",
        "score5 = cross_val_score(rfb, Xpc_train, y_train, cv=kf, scoring='recall')\n",
        "\n",
        "print(\"Training Cross Validation Recall scores are: {}\".format(score5))\n",
        "print(\"Training Average Cross Validation Recall score: {}\".format(score5.mean()))"
      ],
      "metadata": {
        "id": "qeA6_2MHibc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use GridSearch to tune the hyperparameters\n",
        "random_seed = 42\n",
        "grid_rfb = GridSearchCV(rfb, param_grid=params, cv=kf,\n",
        "                          scoring='recall').fit(Xpc_train, y_train)\n",
        "\n",
        "print('Best parameters:', grid_rfb.best_params_)\n",
        "print('Best score:', grid_rfb.best_score_)"
      ],
      "metadata": {
        "id": "o9T6HA89iia9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation metrics\n",
        "random_seed = 42\n",
        "y_pred = grid_rfb.predict(Xpc_test)\n",
        "\n",
        "grid_rfb_Recall = recall_score(y_test, y_pred)\n",
        "grid_rfb_Precision = precision_score(y_test, y_pred)\n",
        "grid_rfb_f1 = f1_score(y_test, y_pred)\n",
        "grid_rfb_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "ROCAUCscore = roc_auc_score(y_test, y_pred)\n",
        "print(f\"AUC-ROC Curve for Random Forest with Class Weights: {ROCAUCscore:.4f}\")\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ],
      "metadata": {
        "id": "wd64wmefiw2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "ndf = [(grid_rfb_Recall, grid_rfb_Precision, grid_rfb_f1, grid_rfb_accuracy)]\n",
        "\n",
        "grid_rfb_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'Accuracy'])\n",
        "grid_rfb_score.insert(0, 'Random Forest with', 'Class weights')\n",
        "grid_rfb_score"
      ],
      "metadata": {
        "id": "W72Seb4ii22d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final summary table\n",
        "predictions = pd.concat([rf_score, over_rf_score, grid_rfb_score], ignore_index=True, sort=False)\n",
        "predictions.sort_values(by=['Recall'], ascending=False)"
      ],
      "metadata": {
        "id": "IiTeSwxwi53n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visulazation of Results**"
      ],
      "metadata": {
        "id": "dpgkdUAAjFUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot of ROC and Precision-Recall curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
        "ax_roc, ax_pr = axes[0], axes[1]\n",
        "\n",
        "classifiers = {\n",
        "    \"Random Forest\": grid_rf,\n",
        "    \"Random Forest with Over Sampling\": grid_over_rf,\n",
        "    \"Random Forest with Class weights\": grid_rfb}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(Xpc_train, y_train)\n",
        "    RocCurveDisplay.from_estimator(clf, Xpc_test, y_test, ax=ax_roc, name=name)\n",
        "    PrecisionRecallDisplay.from_estimator(clf, Xpc_test, y_test, ax=ax_pr, name=name)\n",
        "\n",
        "ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
        "ax_pr.set_title(\"Precision Recall curves\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pCtHW-kViqow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot of Detection-Error curve\n",
        "fig, axes = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax_det = axes\n",
        "classifiers = {\n",
        "    \"Random Forest\": grid_rf,\n",
        "    \"Random Forest with Over Sampling\": grid_over_rf,\n",
        "    \"Random Forest with Class weights\": grid_rfb,\n",
        "        # Add more classifiers here if needed }\n",
        "}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(Xpc_train, y_train)\n",
        "    DetCurveDisplay.from_estimator(clf, Xpc_test, y_test, ax=ax_det, name=name)\n",
        "\n",
        "ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P-ypdc4SjMHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Findings**"
      ],
      "metadata": {
        "id": "XxSfxIf4ANux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Neural Network**\n",
        "\n"
      ],
      "metadata": {
        "id": "N7Et55PPAbF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "iq5vubQQAbF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "ASU8aEGU31mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import utils\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.metrics import Recall, FalseNegatives, AUC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import recall_score, accuracy_score, roc_auc_score\n"
      ],
      "metadata": {
        "id": "y-wVF0HU3_Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Baseline Neural Network**\n",
        "\n",
        "Define a baseline neural network with two layers, one with 100 neurons and a Relu activation function, and an output layer with a Sigmoid activation function.\n",
        "\n",
        "The binary cross-entropy loss function and recall scoring method selected for as best suited for a binary classification with imbalanced data.\n",
        "\n",
        "It isn't obvious which optimizer is best suited to this problem, so we will test three from the Keras libary on the base line model using default settings and compare recall scores:\n",
        "\n",
        "\n",
        "*   Standard Gradient Descent\n",
        "*   RMSprop - adaptive stochastic gradient descent\n",
        "*   Adam - adaptive stochastic gradient descent\n",
        "\n"
      ],
      "metadata": {
        "id": "W12eYTrDA8AL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGD optimizer**"
      ],
      "metadata": {
        "id": "TYnwBN0m1ItP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline model testing SGD optimizer with default values\n",
        "#Define metrics\n",
        "\n",
        "#Define model\n",
        "model = Sequential([\n",
        "        Dense(100, activation = 'relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'sgd',\n",
        "              metrics = ['recall'])\n",
        "\n",
        "class_weight={0: 1, 1: 20}\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "X1RGvyTN5zxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model and view scores\n",
        "#Batch size set by number of columns in Xpc_train\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Convert y_test and Xpc_test to NumPy arrays\n",
        "#y_train = y_train.values\n",
        "#y_test = y_test.values\n",
        "\n",
        "base = model.fit(Xpc_train, y_train,\n",
        "                 epochs = 20,\n",
        "                 batch_size = 22,\n",
        "                 verbose = 0,\n",
        "                 class_weight=class_weight,\n",
        "                 validation_data=(Xpc_test, y_test))\n",
        "#Score the model\n",
        "base.history['recall'][-1]\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YCYQFlrj7Ukt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate AUC score\n",
        "tf.random.set_seed(42)\n",
        "y_pred_probs = model.predict(Xpc_test)\n",
        "sgd_auc_score = roc_auc_score(y_test, y_pred_probs)\n",
        "print(f\"AUC: {sgd_auc_score}\")"
      ],
      "metadata": {
        "id": "ShsEaNdY1q63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model validation and visualization\n",
        "tf.random.set_seed(42)\n",
        "sgd_score = model.evaluate(Xpc_test, y_test, verbose=1)\n",
        "print('Test recall:', sgd_score[1])\n",
        "print('Test loss:', sgd_score[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['recall']), 'r', label='train_recall')\n",
        "ax.plot(np.sqrt(base.history['val_recall']), 'b' ,label='val_recall')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Recall')\n",
        "ax.legend()\n",
        "ax.tick_params()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['loss']), 'r', label='train')\n",
        "ax.plot(np.sqrt(base.history['val_loss']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Loss')\n",
        "ax.legend()\n",
        "ax.tick_params()"
      ],
      "metadata": {
        "id": "dPWNOi6Tlwig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMSprop Optimizer**"
      ],
      "metadata": {
        "id": "Jxz7DTenzmco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a baseline neural network with two layers\n",
        "#Loss functionand scoring selected for binary classification\n",
        "#Testing RMSprop optimizer with default values\n",
        "\n",
        "#Define model\n",
        "model = Sequential([\n",
        "        Dense(100, activation = 'relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics = ['recall'])\n",
        "class_weight={0: 1, 1: 20}"
      ],
      "metadata": {
        "id": "zNoaqCZMzaTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model and view scores\n",
        "#Batch size set by number of columns in Xpc_train\n",
        "tf.random.set_seed(42)\n",
        "base = model.fit(Xpc_train, y_train,\n",
        "                 epochs = 20,\n",
        "                 batch_size = 22,\n",
        "                 verbose = 0,\n",
        "                 class_weight=class_weight,\n",
        "                 validation_data=(Xpc_test, y_test))\n",
        "#Score the model\n",
        "base.history['recall'][-1]"
      ],
      "metadata": {
        "id": "N0oVg4Dhzlai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate AUC score\n",
        "tf.random.set_seed(42)\n",
        "y_pred_probs = model.predict(Xpc_test)\n",
        "rmsprop_auc_score = roc_auc_score(y_test, y_pred_probs)\n",
        "print(f\"AUC: {rmsprop_auc_score}\")"
      ],
      "metadata": {
        "id": "_Ac66W39109N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model validation and visualization\n",
        "tf.random.set_seed(42)\n",
        "rmsprop_score = model.evaluate(Xpc_test, y_test, verbose=1)\n",
        "print('Test recall:', rmsprop_score[1])\n",
        "print('Test loss:', rmsprop_score[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['recall']), 'r', label='train_recall')\n",
        "ax.plot(np.sqrt(base.history['val_recall']), 'b' ,label='val_recall')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Recall')\n",
        "ax.legend()\n",
        "ax.tick_params()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['loss']), 'r', label='train')\n",
        "ax.plot(np.sqrt(base.history['val_loss']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Loss')\n",
        "ax.legend()\n",
        "ax.tick_params()"
      ],
      "metadata": {
        "id": "gtSwZHE0z00O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADAM Optimizer**"
      ],
      "metadata": {
        "id": "KH45xhavz4Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a baseline neural network with two layers\n",
        "#Loss functionand scoring selected for binary classification\n",
        "#Testing RMSprop optimizer with default values\n",
        "\n",
        "#Define model\n",
        "model = Sequential([\n",
        "        Dense(100, activation = 'relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['recall'])\n",
        "class_weight={0: 1, 1: 20}"
      ],
      "metadata": {
        "id": "shU63au-z_Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model and view scores\n",
        "#Batch size set by number of columns in Xpc_train\n",
        "tf.random.set_seed(42)\n",
        "base = model.fit(Xpc_train, y_train,\n",
        "                 epochs = 20,\n",
        "                 batch_size = 22,\n",
        "                 verbose = 0,\n",
        "                 class_weight=class_weight,\n",
        "                 validation_data=(Xpc_test, y_test))\n",
        "#Score the model\n",
        "base.history['recall'][-1]"
      ],
      "metadata": {
        "id": "AvuBJAWfz7YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate AUC score\n",
        "tf.random.set_seed(42)\n",
        "y_pred_probs = model.predict(Xpc_test)\n",
        "adam_auc_score = roc_auc_score(y_test, y_pred_probs)\n",
        "print(f\"AUC: {adam_auc_score}\")"
      ],
      "metadata": {
        "id": "FeEA6Ef03dun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model validation and visualization\n",
        "tf.random.set_seed(42)\n",
        "adam_score = model.evaluate(Xpc_test, y_test, verbose=1)\n",
        "print('Test recall:', adam_score[1])\n",
        "print('Test loss:', adam_score[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['recall']), 'r', label='train_recall')\n",
        "ax.plot(np.sqrt(base.history['val_recall']), 'b' ,label='val_recall')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Recall')\n",
        "ax.legend()\n",
        "ax.tick_params()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(base.history['loss']), 'r', label='train')\n",
        "ax.plot(np.sqrt(base.history['val_loss']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Loss')\n",
        "ax.legend()\n",
        "ax.tick_params()"
      ],
      "metadata": {
        "id": "ZG4f_lIjz6P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table\n",
        "sgd = ['SGD', sgd_score[1], sgd_score[0], sgd_auc_score]\n",
        "rmsprop = ['RMSprop', rmsprop_score[1], rmsprop_score[0], rmsprop_auc_score]\n",
        "adam = ['Adam', adam_score[1], adam_score[0], adam_auc_score]\n",
        "\n",
        "# Create the DataFrame\n",
        "summary = pd.DataFrame(data=[sgd, rmsprop, adam],\n",
        "                      columns=['Optimizer', 'Recall', 'Loss', 'ROC-AUC Score'])\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "UCW_TWCv6wEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Findings**"
      ],
      "metadata": {
        "id": "TBlKeyL1gUR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameter Tuning**\n",
        "\n",
        "We will tune some key parameters of the model using GridSearch for:\n",
        "\n",
        "*   Initialization mode\n",
        "*   Number of neurons\n",
        "*   Batch size\n",
        "\n"
      ],
      "metadata": {
        "id": "olizszTclpGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(units=32):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units, input_dim=22, activation='relu'))\n",
        "    model.add(Dropout(0.3)),\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='bce', optimizer='sgd', metrics=['recall'])\n",
        "    return model\n",
        "\n",
        "# Instantiate the KerasClassifier model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "class_weight={0: 1, 1: 20}\n",
        "#model.summary()\n"
      ],
      "metadata": {
        "id": "E2Rhgqjac7Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {'epochs': [10, 20,30],\n",
        "              'model__units': [50, 100, 150]}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, refit=True)\n",
        "grid.fit(Xpc_train, y_train)"
      ],
      "metadata": {
        "id": "tv2Et1A6dPSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid.best_score_)\n",
        "grid.best_params_"
      ],
      "metadata": {
        "id": "rMO-gmiaecnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import initializers"
      ],
      "metadata": {
        "id": "GX_24V2Okf31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-run the model with tuned parameters\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=22, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='bce', optimizer='rmsprop', metrics=['recall'])\n",
        "class_weight={0: 1, 1: 20}"
      ],
      "metadata": {
        "id": "yI3k2as68ILg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "# Convert y_train to a NumPy array to resolve the issue\n",
        "y_train_np = y_train.values.ravel()\n",
        "\n",
        "tuned = model.fit(Xpc_train, y_train_np,\n",
        "                 epochs = 20,\n",
        "                 batch_size = 22,\n",
        "                 verbose = 1,\n",
        "                 class_weight=class_weight,\n",
        "                 validation_data=(Xpc_test, y_test))"
      ],
      "metadata": {
        "id": "dTUVOG4Z9ZQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate AUC score\n",
        "tf.random.set_seed(42)\n",
        "y_pred_probs = model.predict(Xpc_test)\n",
        "tuned_auc_score = roc_auc_score(y_test, y_pred_probs)\n",
        "print(f\"AUC: {tuned_auc_score}\")"
      ],
      "metadata": {
        "id": "mw_4oCLb-Pka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model validation and visualization\n",
        "tf.random.set_seed(42)\n",
        "tuned_score = model.evaluate(Xpc_test, y_test, verbose=1)\n",
        "print('Test recall:', tuned_score[1])\n",
        "print('Test loss:', tuned_score[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(tuned.history['recall']), 'r', label='train_recall')\n",
        "ax.plot(np.sqrt(tuned.history['val_recall']), 'b' ,label='val_recall')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Recall')\n",
        "ax.legend()\n",
        "ax.tick_params()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "ax.plot(np.sqrt(tuned.history['loss']), 'r', label='train')\n",
        "ax.plot(np.sqrt(tuned.history['val_loss']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch')\n",
        "ax.set_ylabel(r'Loss')\n",
        "ax.legend()\n",
        "ax.tick_params()"
      ],
      "metadata": {
        "id": "OciuDRgE-QKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}